\section{Conclusion}
\label{sec:conclusion}
%(Sam Schmidt, Ofer Lahav, Jeff Newman, Alex Malz, Eve Kovacs, Tony Tyson, Tina Peters)

This paper compares the performance of twelve \pzpdf\ approaches under idealized experimental conditions of representative and complete prior information to set a baseline for an upcoming sensitivity analysis by first isolating the impact of the \pzpdf\ estimation technique from realistic physical systematics of the data.
Though the mock data set of this experiment did not include true \pz\ posteriors for comparison, \textbf{we interpret deviations from perfect results given perfect prior information as the imprint of the implicit assumptions underlying the estimation approach}.

We evaluated the codes under science-agnostic metrics both established and emerging to stress-test the ensemble properties of \pzpdf\ catalogues derived by each method, as well as metrics of a prevalent summary statistic of \pzpdf\ catalogues used in cosmological analyses.
We observe that no one code dominates in all metrics, and that the standard metrics of \pzpdf s and the stacked estimator of the redshift distribution can be gamed by a trivial approach to \pzpdf\ estimation.
We emphasize to the \pz\ community that \textbf{metrics used to vet \pzpdf\ methods must be tailored to science cases with self-consistent analysis approaches that respect the inherently probabilistic nature of \pzpdf\ catalogs}.
