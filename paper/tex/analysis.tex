\section{Analysis}
\label{sec:metrics}

The goal of this study is to evaluate the degree to which \pzpdf s of each method can be trusted for a generic analysis.
The overloaded ``$p(z)$'' is a widespread abuse of notation that obfuscates this goal, so we dedicate attention to dismantling it here.

Galaxies have redshifts $z$ and photometric data $d$ drawn from a joint probability space $p(z, d)$ in nature, and each observed galaxy $i$ has a \textit{true posterior \pzpdf}\ $p(z \vert d_{i})$.
There are a number of metrics that can be used to test the accuracy of a \pz\ posterior as an estimator of a true \pz\ posterior if the true \pzpdf\ is known.
However, the true \pzpdf\ of the observed data is not accessible, as existing mock catalogues produce redshift-photometry pairs $(z, d)$ by a deterministic algorithm that does not correspond to a joint probability density from which one can take samples.
In these cases there is no ``true PDF'' for an individual object
\footnote{\boldblue{While a discrete approximation to the true $p(z,d)$ is possible by sampling the local neighbourhood of parameter space in large datasets with methods like a nearest neighbor or conditional density estimate, we do not make an explicit computation of such an approximate distribution.  Rather, we note that the CMNN and FlexZBoost algorithms are specific implementations of such algorithms which can be used as examples of such approximations in the absence of knowledge of the true $p(z,d)$.}}, and most measures of PDF fidelity will necessarily be restricted to probing the quality of the ensemble of \pzpdf s.
(See \S,\ref{sec:futureexperiments} for a discussion of how one might circumvent this limitation.)

Before describing the metrics appropriate to the DC1 data set, we outline the philosophy behind our choices.
A \pzpdf\ estimator derived by method $H$ must be understood as a posterior probability distribution
\begin{equation}
  \label{eq:pzpdf}
\hat{p}^{H}_{i}(z) \equiv p(z \vert d_{i}, I_{D}, I_{H}),
\end{equation}
conditioned not only on the photometric data $d_{i}$ for that galaxy but also on parameters encompassing prior information $I_{D}$ shared, in our experiment, among all \pzpdf\ codes and $I_{H}$ that will differ depending on the method $H$ used to produce it.
To be concrete, $I_{D}$ takes the form of a training set for the machine learning codes and a template library for the model fitting codes.

The interpretation of the information $I_{H}$ is more subtle.
This investigation is built upon the knowledge that two codes taking the same approach, among choices of model fitting or machine learning, are nonetheless expected to yield different results even if they take the same external prior information $I_{D}$.
$I_{H}$ represents the projection of the code's architecture onto the estimated posteriors over redshift, specific to each code, and even the tunable parameters or random seeds of a specific run of a code with a random component.
We refer to $I_{H}$ as the \textit{implicit prior}, in contrast with the training set or template library provided to a given code explicitly by the researcher.  In simple terms, the implicit prior is the collection of the many different assumptions, coding choices, algorithm selections, and other implementation details that are specific to each code, the ensemble of which results in differing estimates of redshift when combined with the data and prior information in common to all codes.

The presence of the implicit prior in some sense makes a direct comparison of \pzpdf s produced by different methods impossible; even if they share the same external prior information $I_{D}$, by definition they cannot be conditioned on the same assumptions $I_{H}$, otherwise they would not be distinct methods at all.
In this study, we isolate the effect of differences in prior information $I_{H}$ specific to each method by using a single training set $I_{D}^{\mathrm{ML}}$ for all machine learning-based codes and a single template library $I_{D}^{\mathrm{T}}$ for all template-based codes.
These sets of prior information are carefully constructed to be representative and complete, so we have $I_{D} \equiv I_{D}^{\mathrm{ML}} \equiv I_{D}^{\mathrm{T}}$ for every method $H$.
Under this assumption, a ratio of posteriors of codes is in effect a ratio of the implicit posteriors $p(z \vert d_{i}, I_{H'})$ since the external prior information $I_{D}$ is present in the numerator and denominator.
Thus comparisons of $\hat{p}_{i}^{H}(z)$ isolate the effect of the method used to obtain the estimator, which should enable interpretation of the differences between estimated PDFs in terms of the specifics of the method implementations.

The exact implementation of the metrics theoretically depends on the parametrization of the \pzpdf s, which may differ across codes and can affect the precision of the estimator \citep{Malz:2018}.
Even considering a single method under the same parametrization, such as the 200-bin $0 < z < 2$ piecewise constant function used here, the exact bin definitions must affect the result.
The piecewise constant format is chosen because of its established presence in the literature, and the choice of 200 bins was motivated by the approximate number of columns expected to be available for storage of \pzpdf s for the final \lsst\ Project tables.\footnote{See, e.~g.~the \lsst\ Data Products Definition Document, available at: \url{https://ls.st/dpdd}}
We will discuss the choice of \pzpdf\ parameterization further in Section~\ref{sec:discussion}.

This analysis is conducted using the \qp\footnote{\url{http://github.com/aimalz/qp/}}\ software package \citep{Malz:qp} for manipulating and calculating metrics of univariate PDFs.
We present the metrics of \pzpdf s that address our goals in the sections below.
Section~\ref{sec:qualmet} outlines aggregate metrics of a catalogue of \pzpdf s, and Section~\ref{sec:CDE_loss} presents a metric of individual \pzpdf s in the absence of true \pzpdf s.
Those seeking a connection to previous comparison studies will find metrics of redshift point estimate reductions of \pzpdf s in Appendix~\ref{sec:pointmetrics} and metrics of a science-specific summary statistic heuristically derived from \pzpdf s in Appendix~\ref{sec:moments}.

\subsection{Metrics of \pzpdf \ ensembles}
\label{sec:qualmet}

Because \lsst's \pzpdf s will be used for many scientific applications, some of which require each individual catalogue entry to be accurate, we consider several metrics that probe the population-level performance of the \pzpdf s.
As we have the true redshifts but not true \pzpdf s for comparison, we remind the reader of the Cumulative Distribution Function (CDF)
\begin{equation}
  \label{eq:cdf}
  \mathrm{CDF}[f, q] \equiv \int_{-\infty}^{q} f(z) dz,
\end{equation}
of a generic univariate PDF $f(z)$, which is used as the basis for several of our metrics.
We describe metrics based on the CDF in Section~\ref{sec:qqpit} and metrics of summary statistics thereof in Section~\ref{sec:summqqpit}.

\subsubsection{CDF-based metrics}
\label{sec:qqpit}

A quantile of a distribution is the value $q$ at which the CDF of the distribution is equal to $Q$; percentiles and quartiles are familiar examples of linearly spaced sets of 100 and 4 quantiles, respectively.
The quantile-quantile (QQ) plot serves as a graphical visualization for comparing two distributions, where the quantiles of one distribution are plotted against the quantiles of the other distribution, providing an intuitive way to qualitatively assess the consistency between an estimated distribution and a true distribution.
The closer the QQ plot is to diagonal, the closer the match between the distributions.

The probability integral transform (PIT)
\begin{align}
\label{eq:pit}
\mathrm{PIT} &\equiv \mathrm{CDF}[\hat{p}, z_{\mathrm true}]
\end{align}
is the CDF of a \pzpdf\ evaluated at its true redshift, and the distribution of PIT values probes the average accuracy of the \pzpdf s of an ensemble of galaxies.
The distribution of PIT values is effectively the derivative of the QQ plot.
A catalogue of accurate \pzpdf s should have a PIT distribution that is uniform $U(0,1)$, and deviations from flatness are interpretable: overly broad \pzpdf s induce underrepresentation of the lowest and highest PIT values, whereas overly narrow \pzpdf s induce overrepresentation of the lowest and highest PIT values.
Catastrophic outliers with a true redshift outside the support of its \pzpdf\ have $\mathrm{PIT} \approx 0$ or $\mathrm{PIT} \approx 1$.

The PIT distribution has been used to quantify the performance of \pzpdf\ methods in the past \citep[e.~g.~][]{Bordoloi:10,Polsterer:16,Tanaka:17}.
\citet{Tanaka:17} use the histogram of PIT values as a diagnostic indicator of overall code performance, while \citet{Freeman:17} independently define the PIT and demonstrate how its individual values may be used both to perform hypothesis testing (via, e.~g.~ the KS, CvM, and AD tests; see below) and to construct QQ plots.
Following Kodra \& Newman (in prep.) we define the PIT-based catastrophic outlier rate as the fraction of galaxies with $\mathrm{PIT} < 0.0001$ or $\mathrm{PIT} > 0.9999$, which should total 0.0002 for an ideal uniform distribution.

\subsubsection{Summary statistics of CDF-based metrics}
\label{sec:summqqpit}

We evaluate a number of quantitative metrics derived from the visually interpretable QQ plot and PIT histogram, built on the Kolmogorov-Smirnov (KS) statistic
\begin{equation}
  \label{eq:ks}
  \mathrm{KS} \equiv \max_{z} \left( \left| \mathrm{CDF}[\hat{f}, z] - \mathrm{CDF}[\tilde{f}, z] \right| \right),
\end{equation}
interpretable as the maximum difference between the CDFs of the empirical distribution of PIT values for the test sample $\hat{f}(z)$ and a reference distribution $\tilde{f}(z)$, in this case $U(0,1)$, for the ideal distribution of PIT values.
We also consider two variants of the KS statistic.
A cousin of the KS statistic, the Cramer-von Mises (CvM) statistic
\begin{equation}
\label{eq:cvm}
  \mathrm{CvM}^{2} \equiv \int_{-\infty}^{+\infty} \big(\mathrm{CDF}[\hat{f}, z] - \mathrm{CDF}[\tilde{f}, z]\big)^2 \mathrm{d}\mathrm{CDF}[\tilde{f}, z]
\end{equation}
is the mean-squared difference between the CDFs of an approximate and true PDF.
The Anderson-Darling (AD) statistic
\begin{equation} \label{eq:ad}
  \mathrm{AD}^2 \equiv N_{tot}\int_{-\infty}^{+\infty} \frac{\big(\mathrm{CDF}[\hat{f}, z] - \mathrm{CDF}[\tilde{f}, z]\big)^2} {\mathrm{CDF}[\tilde{f}, z] (1 -\mathrm{CDF}[\tilde{f}, z])} \mathrm{d}\mathrm{CDF}[\tilde{f}, z]
\end{equation}
is a weighted mean-squared difference featuring enhanced sensitivity to discrepancies in the tails of the distribution.
In anticipation of a substantial fraction of galaxies having PIT of 0 or 1, a consequence of catastrophic outliers, we evaluate the AD statistic with modified bounds of integration $(0.01, 0.99)$ to exclude those extremes in the name of numerical stability.

\subsection{Conditional Density Estimate (CDE) Loss: a metric of individual \pzpdf s}
\label{sec:CDE_loss}

The \buzz\ simulation process precludes testing the degree to which samples from our \pz\ posteriors reconstruct the space of $p(z, \mathrm{data})$.
To the knowledge of the authors, there is only one metric that can be used to evaluate the performance of individual \pzpdf\ estimators in the absence of true \pz\ posteriors.
The conditional density estimation (CDE) loss is an analogue to the familiar root-mean-square-error used in conventional regression, defined as
\begin{equation}
  \label{eq:cde-loss}
  L(f, \widehat{f}) \equiv \int \int (f(z \vert \x) - \widehat{f}(z \vert \x))^{2} \mathrm{d}z \mathrm{d}P(\x) ,
\end{equation}
where $f(z \vert \x)$ is the true \pzpdf\ that we do not have and $\widehat{f}(z \vert \x)$ is an estimate thereof, in terms of the photometry $\x$.
(See Section~\ref{sec:flexzboost} for a review of the notation.)
We estimate the CDE loss via
\begin{equation}
  \label{eq:estimated-cde-loss}
  \hat{L}(f, \widehat{f}) = \mathbb{E}_\X \left[\int \widehat{f}(z \mid \X)^{2} dz\right] - 2 \mathbb{E}_{\X, Z}\left[\widehat{f}(Z \mid \X)\right] + K_{f},
\end{equation}
where the first term is the expectation value of the \pz\ posterior with respect to the marginal distribution of the photometric covariates $\X$, the second term is the expectation value with respect to the joint distribution of $\X$ and the space $Z$ of all possible redshifts, and the third term $K_{f}$ is a constant depending only upon the true conditional densities $f(z \vert \x)$\xsout{We may estimate these expectations empirically on the test or validation data} \citep[Eq.~7 in][]{Izbicki:17b}. \xsout{without knowledge of the true densities.}
\boldblue{One of the most powerful features of the CDE loss is the ability to estimate the loss function up to a constant even in the absence of knowledge of the true underlying distribution (see Eq.~7 and accompanying discussion in \citet{Izbicki:17} for more details).  This feature enables a quantitative comparison of our estimation methods with our current dataset where we lack access to the true $f(z \vert \x)$.}
