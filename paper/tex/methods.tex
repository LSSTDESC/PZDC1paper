\section{Methods}
\label{sec:pzcodes}

Here we summarize the twelve \pzpdf\ codes compared in this study, summarized in Table~\ref{tab:list_of_codes}, which include both established and emerging approaches in template fitting and machine learning.
Though not exhaustive, this sample represents codes for which there was sufficient expertise within the \lsstdesc\ Photometric Redshifts Working Group; the authors welcome interest from those outside \lsstdesc\ to have their codes assessed in future investigations that build upon this one.

\begin{table*}  %%% DATA TABLE %%%
\caption{List of \pzpdf\ codes featured in this study} \label{tab:list_of_codes}\resizebox{\textwidth}{!}{
\begin{tabular}{lll}
\hline
\bf Published code & \bf Type & \bf Public source code \\
\hline
\lephare~\citep{Arnouts:99}	   & template fitting	& \url{http://www.cfht.hawaii.edu/~arnouts/lephare.html} \\
\bpz~\citep{Benitez:00} 		   & template fitting	& \url{http://www.stsci.edu/~dcoe/BPZ/} \\
\eazy~\citep{Brammer:08}		   & template fitting & \url{https://github.com/gbrammer/eazy-photoz} \\
\annz~\citep{Sadeh:16}		     & machine learning	& \url{https://github.com/IftachSadeh/ANNZ} \\
\flexzboost~\citep{Izbicki:17} & machine learning & \url{https://github.com/tpospisi/flexcode}; \url{https://github.com/rizbicki/FlexCoDE}\\
%\textsc{Frankenz} 	& ML 	& \citet{Speagle:frankenz}	& \url{https://github.com/joshspeagle/frankenz} \\
\gpz~\citep{Almosallam:15b}	   & machine learning	& \url{https://github.com/OxfordML/GPz} \\
\metaphor~\citep{Cavuoti:17}   & machine learning	& \url{http://dame.dsf.unina.it}\\
\cmnn~\citep{Graham:17}        & machine learning & N/A \\
\skynet~\citep{Graff:14}       & machine learning & \url{http://ccpforge.cse.rl.ac.uk/gf/project/skynet/} \\
\tpz~\citep{Carrasco_Kind:13}	 & machine learning	& \url{https://github.com/mgckind/MLZ} \\
\delight~\citep{Leistedt:17}   & hybrid           & \url{https://github.com/ixkael/Delight} \\
\hline
\trainz 	                             & machine learning	& See Section~\ref{sec:method:trainz} \\
\end{tabular}}
\end{table*}

We describe the algorithms and implementations of the model-based and data-driven codes in Sections~\ref{sec:templatecodes} and \ref{sec:trainingcodes} respectively, with a straw-person approach included in Section~\ref{sec:trainz}.
% For each approach, we note how it accounts for photometric uncertainties, how it interprets negative fluxes, what its native output format of \pzpdf s is, and what, if any, preprocessing, including validation, of the prior information it performs.
% In the following sections, we use a consistent notation defined in Table~\ref{tab:variables}.
%
% \begin{table}
% 	\label{tab:variables}
% 	\caption{Definitions of variables used in outlining \pzpdf\ codes}
% 	\begin{tabular}{ll}
% 		\hline
% 		\bf Symbol & \bf Definition \\
% 		\hline
% 		\multirow{ 2}{*}{$b = 1,\dots,B$	& \multirow{ 2}{*}{number $B$ of photometric filters $b$;} \\
% 														& \lsst's $ugrizy$ filters used here correspond to $B=6$ \\
% 		\multirow{ 2}{*}{$m_{b} = 1,\dots,B$	& \multirow{ 2}{*}{number $B$ of photometric filters $b$;} \\
% 																										& \lsst's $ugrizy$ filters used here correspond to $B=6$ \\
% 		$z$											& redshift \\
% 		$T$											& galaxy SED \\
%
% 	\end{tabular}
% \end{table}

\subsection{Template-based Approaches}
\label{sec:templatecodes}

We test three publicly available and commonly used template-based codes that share the standard physically motivated approach of calculating model fluxes for a set of template SEDs on a grid of redshift values and evaluating a \chisq\ merit function using the observed and model fluxes.

\subsubsection{LePhare}
\label{sec:lephare}
%(C\'ecile Roucelle, Eric Nuss, Johann Cohen-Tanugi)

\lephare \footnote{\url{http://www.cfht.hawaii.edu/~arnouts/lephare.html}}\citep[Photometric Analysis for Redshift Estimate,][]{Arnouts:99,Ilbert:06} matches observed colors with those predicted from a template set, which can be semi-empirical or entirely synthetic, directly according to the likelihood $\chi^{2}(z, T, A) \equiv \sum_{b}^{N_{\rm{filt}}} \left((F^{\rm{obs}}_{b} - A F^{\rm{mod}}_{b}(T, z)) / \sigma^{\rm{obs}}_{b}\right)^{2}$ of normalization factor $A$, template $T$, and redshift $z$.
In words, the likelihood is a sum of observed flux error $\sigma_{b}^{\rm{obs}}$-weighted squared differences between the observed flux $F^{\rm{obs}}_{b}$ and the normalized predicted flux $F^{\rm{mod}}_{b}(T, z)$ in $N_{\rm{filt}}$ photometric filters $b$, which is the \lsst\ $ugrizy$ filters in this case.
The reported \pzpdf\ is an arbitrary normalization of the likelihood evaluated on the output redshift grid.
%\textsc{LePhare} has been used to produce the COSMOS2015 photo-$z$ catalogue \citep{Laigle:16}.

Here we use \lephare-v 2.2 with the DC1 template set of Section~\ref{sec:buzztemplates}.

\subsubsection{BPZ}
\label{sec:BPZ}
%(Sam Schmidt)

\bpz \footnote{\url{http://www.stsci.edu/~dcoe/BPZ/}} \citep[Bayesian Photometric Redshift,][]{Benitez:00} determines the likelihood $p(C \vert z, T)$ of a galaxy's observed colours $C$ for a set of SED templates $T$ at redshifts $z$.
The \bpz\ likelihood is related to the \chisq\ likelihood by $p(C \vert z, T) \propto \exp[- \chi^{2} / 2]$.
Given a Bayesian prior $p(z, T \vert m_{0})$ over apparent magnitude $m_0$ and assuming that the SED templates are spanning and exclusive, \bpz\ constructs the redshift posterior $p(z \vert C, m_0)$ by marginalizing over all SED templates as in \citep[Eq.~3 from][]{Benitez:00}, corresponding to setting the parameter \texttt{PROBS\_LITE=TRUE} in the \bpz\ parameter file.
The \bpz\ prior is the product of an SED template proportion that varies with apparent magnitude $p(T \vert m_{0})$ and a prior $p(z \vert T, m_{0})$ over the expected redshift as a function of apparent magnitude and SED template.

Here we test \bpz-v 1.99.3 with the DC1 template set of Section~\ref{sec:buzztemplates}.
To keep the number of free parameters manageable, the DC1 template set is pre-sorted by the rest-frame $u-g$ colour and split into three broad classes of SED template, equivalent to the E, Sp and Im/SB types in .
The Bayesian prior term $p(T \vert m_{0})$ was derived directly from the DC1 training set, and the other term $p(z \vert T, m_{0})$ was chosen to be the best fit for the eleven free parameters of the functional form of \citet{Benitez:00}.
%For photo-$z$ point estimates we use the \texttt{Z\_B} output parameter.
Prior to running the code, the non-detection placeholder magnitude was replaced with an estimate of the one-$\sigma$ detection limit for the undetected band as a proxy for a value close to the estimated sky noise threshold.

\subsubsection{EAZY}
\label{sec:eazy}
%(Rongpu Zhou)

\eazy \footnote{\url{https://github.com/gbrammer/eazy-photoz}} \citep[Easy and Accurate Photometric Redshifts from Yale,][]{Brammer:08} extends the basic \chisq\ fit procedure that defines template-fitting approaches.
The algorithm models the observed photometry with a linear combination of template SEDs at each redshift.
The best-fit SED is found by simultaneously fitting one, two, or all of the templates via \chisq\ minimization, which is distinct from marginalizing across all templates.
The minimized \chisq\ likelihood at each redshift is then combined with an apparent magnitude prior to obtain the redshift posterior PDF.
We note that the utilization of the best-fit SED rather than a proper marginalization does not lead to the correct posterior distribution, an implementation issue that has now been identified and will be addressed by the developers in the future.
\eazy\ can account for uncertainty in the template set by adding in quadrature to the flux errors an empirically derived template error as a function of redshift.

The SED-independent apparent magnitude prior was derived empirically from the DC1 training set.
The \eazy\ architecture cannot accept a template set other than the same five basis templates employed by \texttt{k-correct} when constructing the DC1 catalogue.
However, \eazy\ does feature a flexible \texttt{all-templates} mode, which fits the photometric data with a linear combination of the five basis templates.
We set the template error to zero since the same templates were in fact used to produce the DC1 photometry.

\subsection{Training-based Approaches}
\label{sec:trainingcodes}

We compared nine data-driven \pz\ estimation approaches, eight of which are described in this section and one of which is discussed in Section~\ref{sec:trainz}.
Because the algorithms differ more from one another and the techniques are relative newcomers to the astronomical literature, we provide somewhat more detail about the implementations below.

% Some aspects of data treatment were left to the individual code runners, for example, whether and how to split the DC1 training set for validation.
% The codes considered treated
% Another key difference is the treatment of non-detections in one or more bands.
% Some codes choose to ignore a band, others replace the value with either an estimate for the detection limit, the mean of other values in the training set, or another default value.
% There are varying conventions among training-based codes for treatment of non-detections, and no one prescription dominates in the photo-$z$ literature.
% The specific choices for each code affect the results, and contribute to the implicit prior influencing their output.
% However, we remind the reader that only 2.0 per cent of our sample has non-detections, almost exclusively in the u-band, and thus should not dominate the code performance differences.

\subsubsection{ANNz2}
\label{sec:annz2}
%(John Soo)

\annz \footnote{\url{https://github.com/IftachSadeh/ANNZ}} \citep{Sadeh:16} employs several machine learning algorithms, including artificial neural networks (ANN), boosted decision tree, and k-nearest neighbour (KNN) regression.
In addition to accounting for errors on the input photometry, \annz\ uses the KNN-uncertainty estimate of \citet{Oyaizu:08} to quantify uncertainty in the choice of method over multiple runs.
Using the Toolkit for Multivariate Data Analysis with ROOT\footnote{\url{http://tmva.sourceforge.net/}}, it can return the results of running a single machine learning algorithm, a ``best'' choice of the results from simultaneously running multiple algorithms, or a combination of the results of multiple algorithms weighted by their method uncertainties averaged over multiple runs.
%\textsc{ANNz2} is capable of producing both photo-$z$ point estimates and redshift posterior probability distributions $p(z)$.
% It can also perform classifications, and supports reweighting between samples.
% \annz\ propagates the intrinsic uncertainty on the input parameters and the uncertainty in the machine learning method to the expected photo-$z$ solution, averaged over multiple runs weighted based on the performance of each run.

In this study, we used \annz-v.2.0.4 to output only the result of the ANN algorithm.
\Pzpdf s were produced by running an ensemble of 5 ANNs with a $6:12:12:1$ architecture corresponding to the 6 $ugrizy$ inputs, 2 hidden layers with 12 nodes each, and 1 output of redshift.
Each of the five ANNs was trained with different random seeds for the initialization of input parameters.
Additionally, all ANNs were trained on only a $i \leq 25.3$ subsample of the DC1 training set, and half of the training set was reserved for validation to prevent overfitting.
Undetected galaxies were excluded from the training set, and per-band non-detections in the test set were replaced with the mean magnitude in that band within the entire test set.

\subsubsection{Colour-Matched Nearest-Neighbours}
\label{sec:cmnn}
%(Melissa Graham)

The nearest-neighbours colour-matching photometric redshift estimator \citep[\cmnn,][]{Graham:17} uses a training set of galaxies with known redshifts that has equivalent or better photometry than the test set in terms of quality and filter coverage.
For each galaxy in the test set, \cmnn\ identifies a colour-matched subset of training galaxies using a threshold in the Mahalanobis distance $D_M = \sum_{j}^{N_{\rm colours}} (c^{\rm train}_{j} - c^{\rm test}_{j})^{2} / \delta c_{\rm test}^2$ in the space of available colours $c$, with colour measurement errors $\delta c_{\rm test}$ and $N_{\rm colours} = 5$ colors $j$ defined by the $ugrizy$ filters, which defines the set of colour-matched neighbours based on a value of the percent point function (PPF).
As an example, for $N_{\rm{filt}}=5$ with PPF$=0.95$, $95\%$ of all training galaxies consistent with the test galaxy will have $D_M < 11.07$.
Undetected bands are dropped, thereby reducing the effective $N_{\rm{filt}}$ for that galaxy.
The \pzpdf\ of a given test set galaxy is the normalized distribution of redshifts of its colour-matched subset of training set galaxies.

Here, we make two modifications to the implementation of \citet{Graham:17} to comply with the controlled experimental conditions.
First, we do not impose nondetections on galaxies fainter than the expected \lsst\ 10-year limiting magnitude or bright enough to saturate with \lsst's CCDs, instead using all of the photometry for the DC1 test and training sets.
Second, we apply the initial colour cut to the training set before calculating the Mahalanobis distance in order to accelerate processing and use a magnitude pseudo-prior as in \citet{Graham:17}, but for both we use cut-off values corresponding to the DC1 training set galaxies' colours and magnitudes.

We make an additional adaptation to enable the \cmnn\ algorithm to yield accurate \pzpdf s for all galaxies, as the original \citet{Graham:17} algorithm is optimized for \pz\ point estimates and is susceptible to less accurate \pzpdf s for bright galaxies or those with few matches in colour-space.
We use PPF$=0.95$ rather than PPF$=0.68$ to generate the subset of colour-matched training galaxies, whose redshifts are weighted by their inverse Mahalanobis distances of the when composing the \pzpdf\ rather than weighting all colour-matched training galaxies equally.
Additionally, when the number of colour-matched training set galaxies is less than 20, the nearest 20 neighbours in color-space are used instead, and the output \pzpdf\ is convolved with a Gaussian kernel of variance $\sigma_{\rm train}^{2}({\rm PPF}_{20}/0.95)^2 -1$ to account foe the corresponding growth of the effective PPF to include 20 neighbors.

\subsubsection{FlexZBoost}
\label{sec:flexzboost}
%(Ann Lee, Rafael Izbicki, Taylor Pospisil, Peter Freeman)

\flexzboost \footnote{\url{https://github.com/tpospisi/flexcode};  \url{https://github.com/rizbicki/FlexCoDE} \label{flexzboost_github}} \citep{Izbicki:17} is built on \texttt{FlexCode}, a general-purpose methodology for converting any conditional mean point estimator of $z$ to a conditional density estimator $p(z \vert \x) \equiv f(z \vert \x)$, where $\x$ here represents our photometric covariates and errors.
\flexzboost\ expands the unknown function $f(z \vert \x) = \sum_{i}\beta_{i}(\x)\phi_{i}(z)$ using an orthonormal basis $\{\phi_{i}(z)\}_{i}$.
By the orthogonality property, the expansion coefficients $\beta_{i}(\x) = \mathbb{E}\left[\phi_i(z)|\x\right] \equiv \int f(z \vert \x) \phi_{i}(z) dz$ are thus conditional means.
The expectation value $\mathbb{E}\left[\phi_i(z) \vert \x\right]$ of the expansion coefficients conditioned on the data is equivalent to the regression of the space of possible redshifts on the space of possible photometry.
Thus the expansion coefficients $\beta_{i}(\x)$ can be estimated from the data via regression to yield the conditional density estimate $\widehat{f}(z \vert \x)$.

In this paper, we used \texttt{xgboost} \citep{Chen:16} for the regression; it should however be noted that \texttt{FlexCode-RF}\footref{flexzboost_github}, based on Random Forests, generally performs better for smaller datasets.
As our basis $\phi_{i}(z)$, we choose a standard Fourier basis.
The two tuning parameters in our \pzpdf\ estimate are the number $I$ of terms in the series expansion and an exponent $\alpha$ that we use to sharpen the computed density estimates $\widetilde{f}(z \vert \x) \propto \widehat{f}(z \vert \x)^{\alpha}$.
Both $I$ and $\alpha$ were chosen in an automated way by minimizing the weighted $L_2$-loss function \citep[Eq. 5 in][]{Izbicki:17} on a validation set comprised of a randomly selected 15\% of the DC1 training set.
While \texttt{FlexCode}'s lossless native encoding stores each \pzpdf\ using the basis coefficients $\beta_{i}(\x)$, we discretized the final estimates into 200 linearly-spaced redshift bins $0 < z < 2$ to match the consistent output format of the experimental conditions.

%\subsubsection{Frankenz}
%\label{sec:frankenz}
%(seeking volunteers)
%
%\red{\textsc{Frankenz}\footnote{\url{https://github.com/joshspeagle/frankenz}} \cite{Speagle:frankenz} is...}
%

\subsubsection{GPz}
\label{sec:gpz}
%(Ibrahim Almosallam)

\gpz \footnote{\url{https://github.com/OxfordML/GPz}} \citep{Almosallam:16a,Almosallam:15b} is a sparse Gaussian process based code, a scalable approximation of full Gaussian Processes \citep{Rasmussen:06}, that produces input-dependent variance estimates corresponding to heteroscedastic noise.
The model assumes a Gaussian posterior probability $p(z \vert \x) = \mathcal{N}\left(z \vert \mu(\x), \sigma(\x)^{2}\right)$ of the output redshift $z$ given the input photometry $\x$.
The mean $\mu(\x)$ and the variance $\sigma(\x)^{2}$ are modeled as functions $f(\x) = \sum_{i=1}^{m}w_{i}\phi_{i}(\x)$ linear combinations of $m$ basis functions $\left\{\phi_{i}(\x)\right\}_{i=1}^{m}$ with associated weights $\left\{w_{i}\right\}_{i=1}^{m}$.
% Basis function models, for specific classes of basis functions such as the sigmoid or the squared exponential, have the advantage of being universal approximators, i.e. there exist a function of that form that can approximate any function, with mild assumptions, to any desired degree of accuracy.
The details on how to learn the parameters of the model and the hyper-parameters of the basis functions are described in \citet{Almosallam:15b}.
\gpz's variance estimate is composed of a model uncertainty term corresponding to sparsity of the training set photometry and a noise uncertainty term encompassing noisy photometric observations, enabling quantification of any need for more representative or more precise training samples.
\gpz\ may also weight training set samples by importance according to $|z_{\rm{spec}} - z_{\rm{phot}}| / (1+z_{\rm{spec}})$ to minimize the normalized \pz\ point estimate error, however, this function may be adapted to \pzpdf s, pressuring the model to dedicate more resources to test set galaxies that are not well-represented in the training set.

To smooth the long tail in the distribution of magnitude errors, we use the log of the magnitude errors, improving numerical stability and eliminating the need for constraints on the optimization process.
% We use principal component analysis (PCA) to decorrelate the data
% WHAT IS BEING DECORRELATED HERE?
Unobserved magnitudes $x_{\rm u} = \mu_{\rm u} + \Sigma_{\rm uo}\Sigma_{\rm oo}^{-1}(x_{\rm o} - \mu_{\rm o})$ were imputed from observed magnitudes $x_{\rm o}$ and the training set mean $\mu$ and covariance $\Sigma$ using a linear model.
This is the optimal expected value of the unobserved variables given the observed ones under the assumption that the distribution is jointly Gaussian; note that this reduces to a simple average if the covariates are independent with $\Sigma_{\rm uo} = 0$.
We reserved for validation 20\% of the training set and used the Variable Covariance option in \textsc{GPz} with 200 basis functions, neglecting to apply cost-sensitive learning options.

\subsubsection{METAPhoR}
\label{sec:metaphor}
%(Stefano Cavuoti, Massimo Brescia, Giuseppe Longo)

\textsc{METAPhoR} \citep[Machine-learning Estimation Tool for Accurate Photometric Redshifts,][]{Cavuoti:17} is based on the Multi Layer Perceptron with Quasi Newton Algorithm (MLPQNA) with the least square error model and Tikhonov $L_{2}$-norm regularization \citep{Hofmann:18}.
%, already validated on photo-$z$'s in several cases \citep{de_Jong:17,Cavuoti:17b,Cavuoti:15,Brescia:14,Brescia:13,Biviano:13}.
\Pzpdf s are generated by running $N$ trainings on the same training set, or $M$ trainings on $M$ different random samplings of the training set.
Upon regression of the test set, the photometry $m_{ij}$ of each test set galaxy $j$ in filter $i$ is perturbed according to $m_{ij}' = m_{ij} + \alpha_{i} F_{ij} \epsilon$ in terms of the standard normal random variable $\epsilon \sim \mathcal{N}(0, 1)$, a multiplicative constant $\alpha_{i}$ permitting accommodation of multi-survey photometry, and a bimodal function $F_{ij}$ composed of a polynomial fit of the mean magnitude errors on the binned bands plus a constant term representing the threshold below which the polynomial's noise contribution is negligible \citep{Brescia:18}.
% At a higher level, the pipeline mainly consists of three modules: (i) \textit{data pre-processing}, including a catalogue cross-matching sub-module \citep[based on the tool C3, ][]{Riccio:17}, a sub-module for photometric evaluation and error estimation of the multi-band catalogue used as Knowledge Base (KB), and a sub-module dedicated to the perturbation of the photometric KB, propaedeutic to the PDF estimation; (ii) \textit{photo-$z$ prediction}, which is the training/validation/test phase, producing the photo-$z$'s point estimates, based on a pre-selected ML method; (iii) \textit{PDF estimation}, specifically designed to calculate the PDF of the photo-$z$ estimation errors.
% The last module includes also a post-processing tool, providing some statistics on the produced point estimates and PDFs.

In this work, we used a hierarchical KNN to replace nondetections with values based on their neighbors.
The usual cross-validation step was also omitted for this study.

\subsubsection{SkyNet}
\label{sec:skynet}
%(J. Cohen-Tanugi and Hugo Tranin)

\skynet \footnote{\url{http://ccpforge.cse.rl.ac.uk/gf/project/skynet/}} \citep{Graff:14} employs a neural network based on a second order conjugate gradient optimization scheme \citep[see][for further details]{Graff:14}. %It has been used efficiently for redshift PDF estimates \citep{Sanchez:14,Bonnett:15,Bonnett:16}.
The neural network is configured as a standard multilayer perceptron with three hidden layers and one input layer with 12 nodes corresponding to the 6 photometric magnitudes and their measurement errors.
We use \skynet\ as a regressor for \pz\ point estimation and as a classifier for \pzpdf\ estimation.

The regressor used a standard \chisq\ error function with a single linear node as the output layer and 10 nodes with a $\tanh$ activation function for each hidden layer.
The classifier used a cross-entropy error function with a 20:40:40 node (all rectified linear units) architecture for each hidden layer and an output layer of 200 nodes corresponding to 200 bins for the PDF, with a softmax activation function to enforce the normalization condition that the probabilities sum to unity.
While previous implementations of the code \citep[see Appendix C.3 of~][]{Sanchez:14,Bonnett:15} implement a sliding bin smoothing, no such procedure was used in this study.

We pre-whitened the data by pegging the magnitudes to (45,45,40,35,42,42) and errors to (20,20,10,5,15,15) for $ugrizy$ filters, respectively.
% NO CLUDE WHAT THIS MEANS
To avoid over-fitting, $30\%$ of the training set was reserved for validation, and training was halted as soon as the error rate began to increase on the validation set.
The weights were randomly initialized based on normal sampling.
% WHAT WEIGHTS?

\subsubsection{TPZ}
\label{sec:tpz}
%(Erfan Nourbakhsh)

\textsc{TPZ}\footnote{\url{https://github.com/mgckind/MLZ}} \citep[Trees for Photo-$z$,][]{Carrasco_Kind:13,Carrascokind:14} is a parallel machine learning algorithm that generates photometric redshift PDFs using prediction trees and random forest techniques.
The code recursively splits the input data (i.~e.~the training sample), into two branches, one after another, until a terminal leaf is created that meets a termination criterion (e.~g.~a minimum leaf size or a variance threshold).
Bootstrap samples from the training data and associated errors are used to build a set of prediction trees.
In order to minimize correlation between the trees, the data is divided in such a way that the highest information gain among the random subsample of features is obtained at every point.
The regions in each terminal leaf node corresponds to a specific subsample of the entire data that possesses similar properties.

The training data is examined before running TPZ.
Since TPZ does not handle non-detections (magnitudes flagged as 99.0), we replace these values with an approximation of the $1\sigma$ detection threshold, i.~e.~a signal to noise ratio of 1 in terms of magnitude uncertainty using the equation $dm = 2.5 ~ \log ( 1 + N/S )$ where $dm \sim 0.7526 ~ mag$ for $N/S=1$.
That is, for each band, we replace the non-detection with the magnitude corresponding to the error of 0.7526 from the error model forecasted for 10-year LSST data.
The Out-of-Bag \citep{Breiman:84,Carrasco_Kind:13} cross-validation technique is used within TPZ to evaluate its predictive validity and determine the relative importance of the different input attributes.
We employed this information to calibrate our algorithm.

In the present work, the LSST magnitudes $u,~g,~r,~i$ and colours $u-g,~g-r,~r-i,~i-z,~z-y$ and their associated errors are used in the process of growing 100 trees with a minimum leaf size of 5 (the $z$ and $y$ magnitudes did not show significant correlation with the redshift in our cross-validation, so we did not use them when constructing our trees).
We partitioned our redshift space into 200 bins and smoothed each individual PDF with a smoothing scale of twice the bin size.
%there was a typo here that had 100 bins, I double checked, it is 200 in the final run.

\subsubsection{Delight}
\label{sec:delight}
%(John Soo)

\delight \footnote{\url{https://github.com/ixkael/Delight}} \citep{Leistedt:17} infers \pz s with a data-driven model of latent SEDs and a physical model of photometric fluxes as a function of redshift.
Delight models the underlying latent SEDs as a linear combination of a set of pre-defined template SEDs, plus zero mean Gaussian processes with factorized kernels.
Generally, machine learning methods rely on representative training data with similar band passes, while template based methods rely on a complete library of templates based on physical models constructed.
\textsc{Delight} is constructed in attempt to combine the advantages and eliminate the disadvantages of both template-based and machine learning algorithms: it constructs a large collection of latent SED templates (or physical flux-redshift models) from training data, with a template SED library as a guide to the learning of the model.
The advantage of \textsc{Delight} is that it neither needs representative training data in the same photometric bands, nor does it need detailed galaxy SED models to work.

This conceptually novel approach is done by using Gaussian processes operating in flux-redshift space.
The posterior distribution on the redshift of a target galaxy is obtained via a pairwise comparison with training galaxies,

\begin{equation}
p(z|\mathbf{\hat{F}}) \approx \sum_i p(\mathbf{\hat{F}}|z,t_i)\, p(z|t_i)p(t_i),
\end{equation}
\noindent where $p(z|t_i)p(t_i)$ captures prior information about the redshift distributions and abundances of the galaxies, with $t_i$ denoting the galaxy template; while $p(\mathbf{\hat{F}}|z,t_i)$ is the posterior of noisy flux $\mathbf{\hat{F}}$ at redshift $z$.
For each training-target pair, $p(\mathbf{\hat{F}}|z,t_i)$ is evaluated as follows:
\begin{equation} \label{eq:delight_noisy}
p(\mathbf{\hat{F}}|z,t_i) = \int p(\mathbf{\hat{F}}|\mathbf{F})\, p(\mathbf{F}|z,z_i,\mathbf{\hat{F}}_i)\, d\mathbf{F},
\end{equation}
where $p(\mathbf{\hat{F}}|\mathbf{F})$ is the likelihood function, it compares the noisy real flux $\mathbf{\hat{F}}$ with the noiseless flux $\mathbf{F}$ obtained from the linear combination of template models, carefully constructed to account for model uncertainties and different normalization of the same SED; while $p(\mathbf{F}|z,z_i,\mathbf{\hat{F}}_i)$ is the prediction of flux at a different redshift $z$ with respect to the training object with redshift $z_i$ and flux $\mathbf{\hat{F}}_i$. Eq.~\ref{eq:delight_noisy} is essentially the probability that the training and the target galaxies having the same SED but at a different redshift.
The flux prediction $p(\mathbf{F}|z,z_i,\mathbf{\hat{F}}_i)$ of the training galaxy at redshift $z$ is modeled via a Gaussian process,

\begin{equation} \label{eq:delight_gp}
F_b \sim \mathcal{GP}\left( \mu^F,k^F \right),
\end{equation}
\noindent with mean function $\mu^F$ and kernel $k^F$, both imposed to capture expected correlations resulting from the known underlying physics (i.e., fluxes resulting from observing SEDs through filter response, and the SEDs being redshifted).
The reader should refer to \citet{Leistedt:17} for further details.

In this study, all $100$ ordered Buzzard templates, as described in Section~\ref{sec:buzztemplates}, were used in \textsc{Delight}, and the Gaussian process was trained using the provided training sample.
Photometric uncertainties from the inputs are propagated into the code, while non-detections for each band are set to the mean of the respective bands.
The default settings of \textsc{Delight} were used, with the exception that the PDF bins were set to be linearly-spaced rather than logarithmic. In this study a flat prior in magnitude/type is assumed.

\subsection{trainZ: a straw-person \pz\ estimator}
\label{sec:method:trainz}

In addition to the main photo-$z$ algorithms described above we also include a very simple method as a pathological example.
For \trainz, as we will we call this simple estimator, we well define $p(z)$ as simply:
\begin{equation}
p(z) = \frac{1}{N_{ \mathrm train}}\sum_{\mathrm i=1}^{N_{\mathrm train}}z_{\mathrm train}
\end{equation}
That is, we simply set the redshift PDF of every galaxy equal to the normalized $N(z)$ of the training sample.
This estimator is essentially a k nearest-neighbour estimator with k equal to the number of galaxies in the training sample.
As the training sample is drawn from the same underlying distribution as the test sample, modulo small deviations due to sample size, the quantiles of the training and test distributions should be identical, modulo fluctuations due to finite sample size.
This is a wildly unrealistic estimator, as it assigns all galaxies, no matter their apparent magnitude, colour, or true redshift, the same redshift PDF, and is thus uninformative at the level of individual object redshifts, but is designed to perform very well for the ensemble of all objects.
If the training set was not representative, this estimator would produce biased results, and any attempts to break up the sample into tomographic bins will fail, as every galaxy has an identical $p(z)$.
We will discuss this method and cautions relative to metrics in Section~\ref{sec:caution}.
